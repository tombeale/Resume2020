[
  {
    "LanguageEntryId": 8,
    "Name": "Basic",
    "Key": "vb",
    "BaseYear": 1979,
    "IsEstimate": false,
    "Text": "\u003Cb\u003EBasic\u003C/b\u003E was the first programming language I learned and over the years I worked in several different versions of it on a bunch of different computers including a IBM 1500 Minicomputer, a Timex Sinclair 1000, a bunch of Commodore 64s, a Commodore Amiga, and several flavors of basic on the various PCs I went through.\n\u003Cspace\u003E\nI discovered \u003Cb\u003EVisual Basic\u003C/b\u003E in the early 90\u0027s shortly after \u003Cb\u003EVB 1.0\u003C/b\u003E was released. It was also my first introduction to object-oriented programming concepts, although it wasn\u0027t obvious to me at the time. At that time programming was more of a hobby for me than anything else. I wrote a lot of small desktop utilities such as calculators, music library trackers and phone books.\n\u003Cspace\u003E\nLater on, after switching careers and becoming a full-time developer, I ran into \u003Cb\u003EVB 5/6\u003C/b\u003E executables and DLLs used as COM objects for ASP pages. Corillian made heavy use of the COM objects, as did IAG, where I wrote an installer for their product in VB6. However, most of the server-side objects at IAG were written in VB.Net and instantiated as services using a third-party product. Merrill Corporation had a lot of legacy code written in VB6 which I ended up supporting and modifying when necessary. They were (probably still are) in the process of replacing those applications with something a little more current.\n\u003Cspace\u003E\nI began working with \u003Cb\u003EActive Server Pages (ASP)\u003C/b\u003E in the late 90\u0027s. Up until then, I had been creating websites using HTML and Perl, mostly for my local service provider (Genesis systems in San Dimas California). I was beginning to do some web development informally at McDonnell Douglas, building and maintaining my department\u0027s internal intranet site but at that time web development for me was still a hobby with a mix of freelance work for small companies and churches.\n\u003Cspace\u003E\nThat all changed when I moved my family to Oregon in 2000 and took a full-time web developer position at Corillian Corporation. There I developed online banking sites, using Active Server Pages (ASP) with JavaScript on the front end and VBScript in the back end. There was also a custom version of Basic that was used in their host scripts to communicate with the various bank\u0027s back-ends, usually accomplished by screen-scraping virtual displays generated by a mainframe.\n\u003Cspace\u003E\nAfter being laid off from Corillian in 2004, I went to work with Innovation Asset Group, a start-up in Lake Oswego. There I continued working in ASP on their line-of-business web application, Decipher. Interestingly they were using \u003Cb\u003EVBScript\u003C/b\u003E as the scripting language in the client which restricted it\u0027s use to Internet Explorer only. On the rewrite of the application a few years later, we converted to JavaScript on the client so that the app would work on all browsers. \n\u003Cspace\u003E\n\u003Chr\u003E\nVersions of Basic I used when coding was still just a hobby:\n\u003Cul\u003E\n\u003Cli\u003E\u003Cb\u003EIBM/PC Basic.\u003C/b\u003E\nIn 1991 I bought my first PC. It was a no-name 386DX full tower I had built in one of the local computer shops that were common at that time. It of course had \u003Cb\u003EGW-Basic\u003C/b\u003E but I switched to \u003Cb\u003EQuickBASIC\u003C/b\u003E when it became available. At this time most of my work in basic was just for my personal enjoyment and experimentation.\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003ECommodore Amiga\u003C/b\u003E This was the first serious computer I owned and I worked with two flavors of Basic on it: AmigaBasic and HiSoft Basic (a compiled version of Basic for the Amiga). The Amiga was one of the first computers to have a graphical user interface (and it was in color \u0026#150; the Mac at this time was limited to black and white)\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003ECommodore 64s\u003C/b\u003E Like many machines of it\u0027s day, it used Basic as it\u0027s native operating system. I owned several during the early 80\u0027s - lost track of how many - one would break and I\u0027d buy another at Toys R Us. I had a floppy disk drive, monitor and a printer. Wrote a rudimentary word processor that I used through my senior year of college.\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003EA Timex Sinclair 1000\u003C/b\u003E with 3Kb of memory. I used a cassette tape recorder to save and load programs. It used BASIC as it\u0027s native operating system.\u003C/li\u003E\n\u003Cli\u003EMy introduction to computer programming was in the Army, about six months before my discharge. I was working as the Brigade Draftsman and shared an office with the \u003Cb\u003EIBM 1500 Minicomputer\u003C/b\u003E that was used to generate reports and run the data used in some of the brigade\u0027s war games. I was friends with the operator and I was able to get time regularly on the machine to get a good introduction to BASIC, which like many computers of that time was acting as the machine\u0027s operating system. Initially, programming looked a lot like math to me and I really didn\u0027t thinks I would like it, but once I got the gist of it, it became a life-long obsession. I was hooked.\u003C/li\u003E\n\u003Cul\u003E"
  },
  {
    "LanguageEntryId": 1,
    "Name": "JavaScript",
    "Key": "javascript",
    "BaseYear": 1997,
    "IsEstimate": true,
    "Text": "I have been using JavaScript for a long time. I\u0027m comfortable with the prototypical object model, and I understand closures, asynchronous calls, callbacks and promises. I am comfortable writing JavaScript directly or through TypeScript.\n\u003Cspace\u003E\nI became interested in JavaScript around the time Netscape 4.0 was released. DHTML was the new buzzword and the promise of dynamic web pages was too much to resist. A few years before, I had played with creating Java applets but was disappointed by limitations of the sandbox and slow performance in the browser. JavaScript seemed to have addressed all that. It was fast, it could manipulate DOM object directly and the code was straightforward and simple. Most of my early work was around using mouseover events to display alternate images, client-side validation and opening pop-up windows.\n\u003Cspace\u003E\nDuring this time, I was doing some freelance web development and maintaining a couple of internal web sites at Boeing. It wasn\u0027t until I made the career change from graphic artist to web developer in 2000 that the experience paid off:\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cb\u003ECorillian Corporation\u003C/b\u003E The early sites used a lot of nested frames and iframes to hold content and usually at least one hidden frame that contained JavaScript and was used to maintain state on the client. Most of the content came from the servers using custom templates that resolved tags returned from the Host Interface.\n\u003Cspace\u003E\nLater on, the code used for small banks and credit unions was based on a single-page model that used XML/XLST to display the dynamic content. It also used \u003Cb\u003EJScript\u003C/b\u003E instead of VBScript for server-side scripting. This opened up new possibilities as JScript supported an object-oriented approach that was not possible in VBScript. Eventually the XML was dropped and the dynamic content was generated server-side in JScript.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EInnovation Asset Group\u003C/b\u003E took a different approach, using VBScript to build pages in the client using innerHTML to render sections of the HTML without refreshing the entire frame. A hidden frame was used to hold local state and coordinate changes between other frames. Another hidden frame was used to make server calls. Server-side calls to the data layer returned data serialized using a proprietary data format that basically only added one byte between fields. This was very compact and could be passed into the client and easily deserialized into a two-dimensional array which the client-side code could then use to build tables and other UI components and refresh sections in the main page, much the way an AJAX call would today. Data retrieved from the server was stored in client-side, two-dimensional arrays. A copy of the arrays were also kept to allow the validator to mark fields as dirty if the field content does not match the undo copy.\n\u003Cspace\u003E\nIn the next version of the application, VBScript was replaced with JavaScript so that the application would work in browsers other than IE. I used objects extensively in the client-side code to generate content from data retrieved from the server. This made things a lot more concise easier to maintain. It also meant that when jQuery appeared a few years later, we could use it and that made things a \u003Ci\u003Elot\u003C/i\u003E easier. Portions of the UI were highly customize-able and I built a system of page-specific dialog boxes that would allow the user to make the customizations, provided they had the right permissions.\n\u003Cspace\u003E\nSince the app was now frameless, we went to using AJAX instead of the hidden frame for calls back to the server. A few years later we hired a Java developer who replaced portions of the data layer with a Java service running on a Tomcat server. I worked closely with him. He\u0027s provide me with mock-ups of the JSON he would be returning so I could develop the UI while he developed the back end.  \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E and \u003Cb\u003EMerrill\u003C/b\u003E both were heavily .Net and I didn\u0027t have much opportunity to work in JavaScript as I was scrambling improve my C# skills\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u003C/b\u003E on the other hand was heavily into .Net MVC, but the San Antonio team, who we supported, was developing a new version of their application that uses Angular 2\u002B on the front end. In addition, the local Portland Call Center was developing a replacement for their own application. It was also .Net MVC but it didn\u0027t use Angular. It \u003Ci\u003Edid\u003C/i\u003E use TypeScript in the client. During my time there I had a lot of opportunities to work with TypeScript as a lot of the requests back to the server were AJAX calls and much of the UI components were built on the client.\n\u003C/li\u003E\n\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 3,
    "Name": "ASP (Classic)",
    "Key": "asp",
    "BaseYear": 1998,
    "IsEstimate": true,
    "Text": "I have been using ASP since the late 90s. Even though it\u0027s an older technology, it still shows up every now an then, usually in some legacy application that have matured and is stable enough that no one has been able to make a convincing case to management that it needs to be replaced. My experience with it is as follows:\n\u003Cul\u003E\n\u003Cli\u003E\u003Cb\u003ECorillian Corporation (2000-2004)\u003C/b\u003E\u003Cbr\u003E\nThe bulk of all their online banking sites at this time were ASP coupled with COM objects written  in VB6 or maybe C\u002B\u002B (Not real sure as these were written by another group). There was also a custom version of Basic that was used for the host scripts that pulled data from the banks\u0027 hosts (usually mainframes). I eventually moved into a group that created banking sites for smaller banks and credit unions where the focus was to get the sites done quickly to keep the cost down. These sites were still in ASP but used JScript as the back-end language which I preferred over VBScript that is normally the default.\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003EInnovation Asset Group (IAG) (2004-2014)\u003C/b\u003E\u003Cbr\u003E\nIAG was a startup based in Lake Oswego when I joined the company. As a small company, we had at most 3-4 developers and at some points I was the only developer on the client side. Their main product, Decipher was an ASP-based web application that tracked patent, trademark and invention disclosure data. It had a data layer and a valuation layer, both written in VB.Net which ran as windows services using a third-party wrapper (at that point VB.Net did not support running as a service natively). The initial version used VBScript as the client-side language, which limited the browser it could be used with to IE6. \n\u003Cspace\u003E\nA rewrite several years later switched it to JavaScript and most of the pages used JScript in the back-end as well. JQuery and AJAX were used extensively throughout the application using an efficient custom serialization of the table data using the binary characters 1, 2 and 3 to separate table, row and field data respectively. Pages were rendered in the client, usually using an object that contained an array of rows, which in turn objects that contain an array of fields plus the logic to render the rows. The parent object would render the table and iterate through the objects which would render the rows.\n\u003Cspace\u003E\nI also created an extensive set of debugging and configuration tools that allowed uses to configure the application, add data fields and modify some screens as well as display in-memory data in tabular format. All this was based on user/group permissions.  \n\u003Cspace\u003E\nAt one point, the developers who wrote and managed the data and valuation layers left the company and it was decided to replace the aging VB.Net components with a new back-end based on a Tomcat server and Java. I was responsible for the client side and used AJAX to make REST calls to the back-end.   \n\u003C/li\u003E\n\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 9,
    "Name": "SQL",
    "Key": "sql",
    "BaseYear": 1998,
    "IsEstimate": false,
    "Text": "Not sure exactly when I started using SQL. I know it was probably around 1998 as I was still in California doing development on a Linux server for some local websites. At that time I was doing a lot of PHP/MySQL.\n\u003Cspace\u003E\nSQL has been a staple part of my development from the day I picked it up. I must have written thousands of queries to explore databases, create test data, test program execution and check results, even when I\u0027m using Entity Framework for my actual development. Professionally, I\u0027ve used it all through my career:\n\u003Cul\u003E\u003Cli\u003E\nWhen I went to work at \u003Cb\u003ECorillian\u003C/b\u003E in 2000, I wrote a lot of scripts against Microsoft SQL Server databases, mostly to support development. \n\u003C/li\u003E\u003Cli\u003E\nAt \u003Cb\u003EInnovation Asset Group\u003C/b\u003E (IAG) the emphasis was to write generic scripts that would work on both MySQL and MS Server as the main product, Decipher, could be installed to use either database engine. IAG didn\u0027t have a dedicated DB Analyst, so I ended up doing a lot of database installs and configuration, not to mention finding ways to optimize queries for both SQL Server \u003Ci\u003Eand\u003C/i\u003E MySQL.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E was already using Entity Framework in their main applications, but there was still a lot of SQL in the utility applications.\n\u003C/li\u003E\u003Cli\u003E\nAt \u003Cb\u003EMerrill Corporation\u003C/b\u003E I created and edited a lot of stored procedures which were used in the legacy product and the file interfaces to pull data from customer-provided text files and save it to the database. The product dealt with large volumes of insurance data and I often had to find ways to optimize the stored procedures to improve performance.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u003C/b\u003E used stored procedures in their APIs and some of the legacy applications used SQL with parameterized queries. I created, edited and debugged these stored procedures on a daily basis. \n\u003C/li\u003E\u003C/ol\u003E\n"
  },
  {
    "LanguageEntryId": 10,
    "Name": "Cascading Style Sheets (CSS)",
    "Key": "css",
    "BaseYear": 1998,
    "IsEstimate": false,
    "Text": "I was a graphic artist before I became an application developer. Most professional-level graphics and publishing software in the late 80\u0027s used style sheets so when CSS came into use in HTML, it was a familiar concept to me. Fortunately, by June of 2000, when I moved to Oregon and took my first job as a web developer, CSS in it\u0027s basic form was more-or-less stable but limited. There was a lot of fiddling around with JavaScript, tables and every other trick we could think of to get things to look and behave right, especially when supporting multiple browsers. \n\u003Cspace\u003E \nI have been using style sheets on a daily basis since I began working as a web developer. Over the years CSS has continually evolved and stabilized. Milestones include:\n\u003Cul\u003E\u003Cli\u003E\nIt was with the release of \u003Cb\u003EjQuery\u003C/b\u003E that I really understood the power of selectors. Being able to apply a style or perform a DOM operation against a list of elements in one line of code was phenomenal. Also, realizing that applying a class to an element doesn\u0027t require to actually be defined was \u003Ci\u003Ehuge\u003C/i\u003E. The class selectors could be used as arbitrary tags, allowing any number of otherwise unconnected elements to be selected as a group and acted upon.\n\u003C/li\u003E\u003Cli\u003E\nThe appearance of Chrome leveled the playing field. The browser became the de-facto standard in a remarkably short time. The first time I heard about it when I learned the marketing team at IAG was using it for their demos because it was faster and more stable than the other browsers. The fact that the development team didn\u0027t even know about it (and obviously didn\u0027t code for it) was beyond impressive. Google\u0027s no-nonsense policies for constantly updating chrome automatically have been a major force for implementing standards. The other browsers \u003Ci\u003Ehave\u003C/i\u003E to comply to remain competitive.\n\u003C/li\u003E\u003Cli\u003E\nUsing the @media tag together with flex layouts (divs instead of tables) made \u003Cb\u003Eresponsive page layouts\u003C/b\u003E possible. Using the animation properties of classes made it elegant.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ECSS3\u003C/b\u003E improved things, standardizing a lot of tags that were previously browser-specific, adding transitions when classes are added or removed dynamically, shadows, native support for SVG and Canvas.\n\n\n\u003C/li\u003E\u003C/ul\u003E\n"
  },
  {
    "LanguageEntryId": 4,
    "Name": "AJAX/WebAPI",
    "Key": "ajax",
    "BaseYear": 2006,
    "IsEstimate": true,
    "Text": "I have been using AJAX or similar technologies for about as long as it\u0027s been around:\n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E was rewriting their existing ASP.Net applications to .Net MVC with an Angular UI. This used AJAX extensively, often using AJAX in two different tiers. The Angular UI communicates back to the MVC framework through AJAX calls to API controllers, which then pass the requests down to the business layer. If the data requested is served from a remote server such as the Portland Call Center, the business layer will then make another AJAX call to the web service on that server.\n\u003Cspace\u003E\nI was involved an all facets of this process, sometimes creating new end-to-end functionality including the API and all the components including the Angular UI. I worked in the Portland Call Center and worked on San Antonio applications remotely. Testing and debugging the APIs independently was accomplished using Swagger locally.\n\u003Cspace\u003E\nThe Portland Call Center was also rewriting of their own application, replacing legacy ASP.Net with .Net Core MVC. This did not use Angular, but it did use TypeScript in the front end. Data operations were a mix of MVC and AJAX, depending on the the page requirements.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EMerrill Corporation\u003C/b\u003E was more traditional in their client/server approach. I don\u0027t remember much AJAX being implemented there at all.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis Financial Solutions\u003C/b\u003E \u003Ci\u003Edid\u003C/i\u003E have a lot of .Net WebAPIs which usually served as the data layer for multiple applications. They had MVC index pages incorporated into the service that briefly documented the API and allowed for some testing/debugging. \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EInnovation Asset Group\u003C/b\u003E originally used a pseudo-AJAX approach using a hidden frame in the first version of their product. When the application was re-written, we began using AJAX calls (based at first on our own code and later using jQuery\u0027s Ajax methods) to ASP pages that would make the call to the data layer and return serialized data. This data was then deserialized in the client using JavaScript and used to re-draw sections of the page using document.innerHTML. As the application matured, more and more of the data layer was moved to API calls, creating a very clear line between the Client and Server sides of the application.\n\u003Cspace\u003E\nLater on, we added a new reporting engine using Java on a Tomcat server. This was when the AJAX model really paid off as no real work was required to adapt to the new data source; all it took was using the new REST URL and adding methods to serialize/deserialize JSON. We \u003Ci\u003Edid\u003C/i\u003E have to enable URL re-writing on the web server and there was some fiddling with the headers to get the session right. \n\u003C/li\u003E\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 1010,
    "Name": "jQuery",
    "Key": "jquery",
    "BaseYear": 2006,
    "IsEstimate": false,
    "Text": "I began using jQuery shortly after its release while working at \u003Cb\u003EInnovation Asset Group\u003C/b\u003E. At first I was a bit skeptical, but it did such a good job at wrapping the CSS queries and interacting with the DOM that it\u0027s usually worth it to include the 100-200kb library.j\n\u003Cspace\u003E\nQuery is actually written in JavaScript, so it isn\u0027t really adding anything to the language, but it makes it easy to do things that would be difficult or impractical to do otherwise. It\u0027s wicked fast and provides cross-browser support:\n\u003Cul\u003E\u003Cli\u003E\nI use jQuery for almost all of my AJAX code from the client. It is very easy to set up, allows you pass in the callback functions and it returns a promise which lets the callbacks to be called in their local scope.\n\u003C/li\u003E\u003Cli\u003E\nI use jQuery to add and remove classes from elements or groups of elements. If the CSS is set up right, this will trigger animations as elements grow or shrink, move for one location to another or fade from one color to another.\n\u003C/li\u003E\u003Cli\u003E\nI sometimes use jQuery to add event handlers to elements based on a CSS class or Id.\n\u003C/li\u003E\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 2,
    "Name": "C#",
    "Key": "c",
    "BaseYear": 2011,
    "IsEstimate": true,
    "Text": "C# has been my primary, day-to-day language for the last six years. Before that I used it on a sporadic basis creating back-end utilities and debugging tools.\n\u003Cul\u003E\u003Cli\u003E\nAt \u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E, I used C# with Visual Studio, version 2017 and 2019 on a daily basis (sometimes using an older version to work on legacy code). The emphasis was on clean, concise code that was easy to maintain and adhered to the established best practices. I worked with several groups, including offshore teams using an Agile process that was efficient and well established using three-week sprints. Source code was managed through Git and many of the projects in the lower regions (dev, integration and release) used Continuous Integration. Higher regions (beta and production) were deployed automatically, but required a manual launch. The projects included Web APIs, building business, data and service layers, writing MVC controllers and solving business, performance and security issues. I interfaced routinely with SQL Server using Entity Framework/Link and sometimes calling stored procedures (usually in the APIs). Most of the applications were .Net MVC or .Net Core MVC but occasionally I would need to work on a legacy application written in ASP.Net (WebForms/ASPX).\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EMerrill Corporation\u003C/b\u003E was interesting. Projects there ranged from .Net MVC Core to Classic ASP with COM objects written in Visual Basic 6. Their main product was a collection of applications that assembled insurance information and generated large, data-intensive documents like Group Insurance Plans, Benefits Packages and voting pamphlets. They were rewriting the UI for their main product from ASP.Net to .Net MVC. In addition to these, there were many other projects for compiling data based on institution/group-specific data, verifying the integrity of the data and formatting the data into printer files (PDFs) and File Interfaces which were the applications that would take customer-provided files. The latter could be comma or tab-delimited, XML, or sometimes a custom format that would require writing a custom parser. \n\u003Cspace\u003E\nI was involved in many of these, creating pages for the UI rewrite, creating a couple file interfaces and made bug fixes several more. I wrote routines and made changes to several of the data-assembly projects and of course did a lot of bug fixes. One file-interface project I wrote involved importing XML files that were over four GB in size (minified, with no unnecessary white space or line breaks). I had to write a custom parser that would go through the file serially on an element-by-element basis and saving the relevant data as it was found. I re-used this code to write a windows forms app that could search through the file and display matching records in a tabular format. This was necessary as no one had a viewer that could open the file and format the XML. This utility was used by the Integration and QA groups to investigate data-import issues.\n\u003Cspace\u003E\nLater projects were done using a test-driven development pattern, using the test cases to develop the components. I was shocked when the components were integrated with no bugs. We used a fake DB, which means that every test group re-created the tables and populated the data it needed. It was definitely worth it in the end.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis Financial Solutions\u003C/b\u003E provides low-maximum credit cards for companies, such as furniture stores and other retailers that issue them to customers who otherwise would have a hard time getting credit. The group I worked for was responsible for creating and maintaining software used by the company\u0027s call center. I was there on a three-month contract during which I got a crash course on the finer points of C# such as lambda expressions, Entity Framework and how large .Net applications should be structured. I was involved in a couple of .Net MVC projects, plus wrote several back-end utilities that extracted data from large files or managed the files referenced by these files.\n\u003C/li\u003E\u003Cli\u003E\nAlthough most of my work at \u003Cb\u003EInnovation Asset Group\u003C/b\u003E was in JavaScript, there was an occasional file interface that needed to be written to deal with flat files provided by the customers. Usually these were C# console apps that could be kicked off by a scheduled task, but sometimes they included a Windows Form UI to allow options to be set or the progress to be monitored. Often these files would only loosely conform to the format they provided and in one case the format would change from section to section as it was a collection of files from various department that each had their own way of doing things. Being such a small company (usually less than 10 employees) it was easier to just accommodate our clients (who tended to be very large corporations) than to try an enforce policies on the data formats we would accept.\n\u003C/li\u003E\u003C/ul\u003E\nBeyond my professional experience, I\u0027ve used several versions of C since the late 1980\u0027s.\n\u003Cul\u003E\u003Cli\u003E\nI first learned C on the Commodore Amiga using the Lattice C Compiler. The Amiga, although powerful for its day had no concept of protecting memory. Address 4 was the only address that could not be written to by the user, which means that if you declare a string pointer and try to load data into it with out first allocating the memory, it would take whatever the value of the pointer is (usually a random number) and overwrite whatever was was in memory, starting at that address. Unless you were \u003Ci\u003Ereally\u003C/i\u003E lucky, this usually resulted in one of three errors: \n\u003Col\u003E\u003Cli\u003E\nThe cursor disappears and never comes back.\n\u003C/li\u003E\u003Cli\u003E\nYou get the \u0027Guru Meditation\u0022 message at the top of the screen (the Amiga equivalent of the \u0022Blue Screen of Death\u0022.\n\u003C/li\u003E\u003Cli\u003E\nYou get \u0022Fireworks Display Mode\u0022 which is what happens when you overwrite display memory or logic with random data.\n\u003C/li\u003E\u003C/ol\u003E\nAll three of these required hard boot to recover and any unsaved anything was gone.\n\u003Cspace\u003E\nI took a class at Sun Microsystems through McDonnell Douglas and that really made the language clear to me, especially how pointers and memory management work. After that, I was hooked. I wrote some utilities for the Amiga Workbench (More like filling out taxes than programming at times) and a text reader I wrote was used in the floppy-based Amiga magazine published in Ranch Cucamonga  \u003Ci\u003EJump Disk\u003C/i\u003E for a few years.\n\u003C/li\u003E\u003Cli\u003E\nI did some C on Sun workstations at McDonnell Douglas \u2013 the Interleaf Publishing System ran on Sun workstations and used LISP as it\u0027s scripting language (don\u0027t get me started on LISP). I learned in LISP was how to write a function to call a C program. After that, since Sun UNIX included a native c compiler, I made all my scripts in C. These could be launched from Interleaf\u0027s menu system and included mostly utility scripts and a filter to convert a TIFF image to the native Interleaf raster format. \n\u003C/li\u003E\u003Cli\u003E\nWhen I moved to the PC and Windows, I did some coding with Quick C, Quick C for Windows and Visual C\u002B\u002B 5.0 with the Microsoft Foundation Classes (MFC). However C and MFC just weren\u0027t a good fit what I needed as I was moving toward web development, so I shelved C for a while and moved on to other languages with a similar syntax like JavaScript, PERL and PHP.\n\u003C/li\u003E\u003C/ul\u003E\n"
  },
  {
    "LanguageEntryId": 6,
    "Name": "TypeScript",
    "Key": "typescript",
    "BaseYear": 2014,
    "IsEstimate": false,
    "Text": "I did quite a bit of TypeScript development during my time at \u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E (SWBC)\n\u003Cul\u003E\u003Cli\u003E\nThe main SWBC development group in San Antonio, Texas uplifted their legacy applications to a new set of applications (Portal) using .Net MVC/WebAPI on the back-end and Angular 4 for the UI which uses TypeScript. The application used MVC to build the pages and load the initial data which was serialized as part of the HTML. Once the page was built, the Angular/TypeScript took over and handled user request, using Angular\u0027s AJAX methods to call the WebAPI, which in turn performed any server-side operations that were needed then either navigated to another page through MVC or returned JSON back to the client and Angular would decide what to do next. I was involved in implementing the application maintained by the Portland Call Center as part of the Portal application.\n\u003C/li\u003E\n\u003Cli\u003E\nThe development team for the Portland Call Center began a project to uplift their product, SureTrack from ASP.Net to .Net Core MVC. This did not use Angular, but it \u003Ci\u003Edid\u003C/i\u003E use TypeScript and I did a lot of the client-side development. This was an interesting project as it gave me a chance to use TypeScript outside the Angular environment. I wrote several basic components including a tab control and a grid control. Unfortunately, in October, 2019, the Portland Call Center was closed and the project abandoned. The development team was retained as remote employees, but moved on to other projects in support of the San Antonio Team.\n\u003C/li\u003E\n\u003C/ul\u003E\nI have mixed feelings about TypeScript. It \u003Ci\u003Eseems\u003C/i\u003E like it\u0027s aimed at C#/Java developers that can\u0027t get their heads around the prototypical inheritance model that JavaScript uses. However, coming from JavaScript development, it feels a bit like learning German to write documentation in German so it can be translated back to my native English. I worry that it will lead to a generation of web developers that understand TypeScript, but don\u0027t understand the nuts and bolts of JavaScript. It\u0027s the quirks in JavaScript that really gives it it\u0027s power.\n\u003Cspace\u003E\nOn the other hand, it \u003Ci\u003Edoes\u003C/i\u003E make for elegant source code (yes, even if carefully written, JavaScript can be a bit cryptic and in the wrong hands can lead to some marvelously undecipherable code), and developers familiar with C#/Java will have a much easier time figuring it out."
  },
  {
    "LanguageEntryId": 7,
    "Name": "Entity Framework (EF)",
    "Key": "ef",
    "BaseYear": 2014,
    "IsEstimate": false,
    "Text": "Although I was skeptical at first, Entity Framework has proven to be  \n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E gave me my first exposure to EF, mostly through making changes to existing code. That\u0027s also where I was first exposed to lambda expressions in C#. By the time I left Genesis, I hadn\u0027t mastered it yet, but I was definitely intrigued. \n\u003C/li\u003E\u003Cli\u003E\nI got a lot more exposure to EF at \u003Cb\u003EMerrill Corporation\u003C/b\u003E.They used a database-first approach and had a very large and complex database which was pushing the limits of what Visual Studio\u0027s EDMX interface [refine this] could manage. One of the members on my team wrote an EDMX generator that would generate the EDMX code as part of a build, saving us a lot "
  }
]