[
  {
    "LanguageEntryId": 8,
    "Name": "Basic",
    "Key": "vb",
    "BaseYear": 1979,
    "IsEstimate": false,
    "Text": "\u003Cb\u003EBasic\u003C/b\u003E was the first programming language I learned and over the years I worked in several different versions of it on a bunch of different computers including a IBM 1500 Minicomputer, a Timex Sinclair 1000, a bunch of Commodore 64s, a Commodore Amiga, and several flavors of basic on the various PCs I went through.\n\u003Cspace\u003E\nI discovered \u003Cb\u003EVisual Basic\u003C/b\u003E in the early 90\u0027s shortly after \u003Cb\u003EVB 1.0\u003C/b\u003E was released. It was also my first introduction to object-oriented programming concepts, although it wasn\u0027t obvious to me at the time. At that time programming was more of a hobby for me than anything else. I wrote a lot of small desktop utilities such as calculators, music library trackers and phone books.\n\u003Cspace\u003E\nLater on, after switching careers and becoming a full-time developer, I ran into \u003Cb\u003EVB 5/6\u003C/b\u003E executables and DLLs used as COM objects for ASP pages. Corillian made heavy use of the COM objects, as did IAG, where I wrote an installer for their product in VB6. However, most of the server-side objects at IAG were written in VB.Net and instantiated as services using a third-party product. Merrill Corporation had a lot of legacy code written in VB6 which I ended up supporting and modifying when necessary. They were (probably still are) in the process of replacing those applications with something a little more current.\n\u003Cspace\u003E\nI began working with \u003Cb\u003EActive Server Pages (ASP)\u003C/b\u003E in the late 90\u0027s. Up until then, I had been creating websites using HTML and Perl, mostly for my local service provider (Genesis systems in San Dimas California). I was beginning to do some web development informally at McDonnell Douglas, building and maintaining my department\u0027s internal intranet site but at that time web development for me was still a hobby with a mix of freelance work for small companies and churches.\n\u003Cspace\u003E\nThat all changed when I moved my family to Oregon in 2000 and took a full-time web developer position at Corillian Corporation. There I developed online banking sites, using Active Server Pages (ASP) with JavaScript on the front end and VBScript in the back end. There was also a custom version of Basic that was used in their host scripts to communicate with the various bank\u0027s back-ends, usually accomplished by screen-scraping virtual displays generated by a mainframe.\n\u003Cspace\u003E\nAfter being laid off from Corillian in 2004, I went to work with Innovation Asset Group, a start-up in Lake Oswego. There I continued working in ASP on their line-of-business web application, Decipher. Interestingly they were using \u003Cb\u003EVBScript\u003C/b\u003E as the scripting language in the client which restricted it\u0027s use to Internet Explorer only. On the rewrite of the application a few years later, we converted to JavaScript on the client so that the app would work on all browsers. \n\u003Cspace\u003E\n\u003Chr\u003E\nVersions of Basic I used when coding was still just a hobby:\n\u003Cul\u003E\n\u003Cli\u003E\u003Cb\u003EIBM/PC Basic.\u003C/b\u003E\nIn 1991 I bought my first PC. It was a no-name 386DX full tower I had built in one of the local computer shops that were common at that time. It of course had \u003Cb\u003EGW-Basic\u003C/b\u003E but I switched to \u003Cb\u003EQuickBASIC\u003C/b\u003E when it became available. At this time most of my work in basic was just for my personal enjoyment and experimentation.\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003ECommodore Amiga\u003C/b\u003E This was the first serious computer I owned and I worked with two flavors of Basic on it: AmigaBasic and HiSoft Basic (a compiled version of Basic for the Amiga). The Amiga was one of the first computers to have a graphical user interface (and it was in color \u0026#150; the Mac at this time was limited to black and white)\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003ECommodore 64s\u003C/b\u003E Like many machines of it\u0027s day, it used Basic as it\u0027s native operating system. I owned several during the early 80\u0027s - lost track of how many - one would break and I\u0027d buy another at Toys R Us. I had a floppy disk drive, monitor and a printer. Wrote a rudimentary word processor that I used through my senior year of college.\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003EA Timex Sinclair 1000\u003C/b\u003E with 3Kb of memory. I used a cassette tape recorder to save and load programs. It used BASIC as it\u0027s native operating system.\u003C/li\u003E\n\u003Cli\u003EMy introduction to computer programming was in the Army, about six months before my discharge. I was working as the Brigade Draftsman and shared an office with the \u003Cb\u003EIBM 1500 Minicomputer\u003C/b\u003E that was used to generate reports and run the data used in some of the brigade\u0027s war games. I was friends with the operator and I was able to get time regularly on the machine to get a good introduction to BASIC, which like many computers of that time was acting as the machine\u0027s operating system. Initially, programming looked a lot like math to me and I really didn\u0027t thinks I would like it, but once I got the gist of it, it became a life-long obsession. I was hooked.\u003C/li\u003E\n\u003Cul\u003E"
  },
  {
    "LanguageEntryId": 1013,
    "Name": "HTML",
    "Key": "html",
    "BaseYear": 1994,
    "IsEstimate": false,
    "Text": "For over twenty years I have been working in HTML full time on a daily basis. \n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003ECreating and modifying HTML is the foundation of what I do\u003C/b\u003E\u003Cbr\u003E\nI usually create HTML in either Notepad\u002B\u002B or Visual Studio, depending on whether it\u0027s part of a .Net project or not.\nOften, I\u0027m writing code to generate it in either C# and JavaScript, although I have used Perl, VBScript, JScript and PHP.\n\u003C/li\u003E\u003Cli\u003E\n\n\u003Cb\u003EI have a lot of experience creating and using templates\u003C/b\u003E\u003Cbr\u003E\nI have used templates in Handlebars, Angular, Razor, ASP.Net, ASP and PHP. I have also written custom code to create templates when needed.\n\u003C/li\u003E\u003Cli\u003E\n\n\u003Cb\u003EI have a solid understanding of the DOM\u003C/b\u003E\u003Cbr\u003E\nI\u0027ve done just about everything from changing images and background colors to creating rich graphical interfaces with draggable elements and dynamic content.\n\u003C/li\u003E\u003Cli\u003E\n\n\u003Cb\u003EI Understand REST and GET, POST, PUT, and DELETE\u003C/b\u003E\u003Cbr\u003E\nI know how to pull GET and POST information in low-level languages such as PERL or C, but also understand the modern REST semantic conventions and when to use GET, POST, PUT, and DELETE and how the API should behave for each  method.\n\u003C/li\u003E\u003Cli\u003E\n\n\u003Cb\u003EI am familiar with security issues related to HTTP and HTML plus how to defend against them\u003C/b\u003E\u003Cbr\u003E\nI\u0027ve had a lot of classes and practical experience with validating and sanitizing content to prevent cross-site scripting and SQL Injection. I am familiar with HTTP security headers plus the problems they cause if used incorrectly. Basically it all comes down to common sense and ensuring best practices are in used consistently.\n\n\u003C/li\u003E\u003C/ul\u003E\n"
  },
  {
    "LanguageEntryId": 1,
    "Name": "JavaScript",
    "Key": "javascript",
    "BaseYear": 1997,
    "IsEstimate": true,
    "Text": "I have been using JavaScript for a long time. I\u0027m comfortable with the prototypical object model, and I understand closures, asynchronous calls, callbacks and promises. I am comfortable writing JavaScript directly or through TypeScript.\n\u003Cspace\u003E\nI became interested in JavaScript around the time Netscape 4.0 was released. DHTML was the new buzzword and the promise of dynamic web pages was too much to resist. A few years before, I had played with creating Java applets but was disappointed by limitations of the sandbox and slow performance in the browser. JavaScript seemed to have addressed all that. It was fast, it could manipulate DOM object directly and the code was straightforward and simple. Most of my early work was around using mouseover events to display alternate images, client-side validation and opening pop-up windows.\n\u003Cspace\u003E\nDuring this time, I was doing some freelance web development and maintaining a couple of internal web sites at Boeing. It wasn\u0027t until I made the career change from graphic artist to web developer in 2000 that the experience paid off:\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cb\u003ECorillian Corporation\u003C/b\u003E The early sites used a lot of nested frames and iframes to hold content and usually at least one hidden frame that contained JavaScript and was used to maintain state on the client. Most of the content came from the servers using custom templates that resolved tags returned from the Host Interface.\n\u003Cspace\u003E\nLater on, the code used for small banks and credit unions was based on a single-page model that used XML/XLST to display the dynamic content. It also used \u003Cb\u003EJScript\u003C/b\u003E instead of VBScript for server-side scripting. This opened up new possibilities as JScript supported an object-oriented approach that was not possible in VBScript. Eventually the XML was dropped and the dynamic content was generated server-side in JScript.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EInnovation Asset Group\u003C/b\u003E took a different approach, using VBScript to build pages in the client using innerHTML to render sections of the HTML without refreshing the entire frame. A hidden frame was used to hold local state and coordinate changes between other frames. Another hidden frame was used to make server calls. Server-side calls to the data layer returned data serialized using a proprietary data format that basically only added one byte between fields. This was very compact and could be passed into the client and easily deserialized into a two-dimensional array which the client-side code could then use to build tables and other UI components and refresh sections in the main page, much the way an AJAX call would today. Data retrieved from the server was stored in client-side, two-dimensional arrays. A copy of the arrays were also kept to allow the validator to mark fields as dirty if the field content does not match the undo copy.\n\u003Cspace\u003E\nIn the next version of the application, VBScript was replaced with JavaScript so that the application would work in browsers other than IE. I used objects extensively in the client-side code to generate content from data retrieved from the server. This made things a lot more concise easier to maintain. It also meant that when jQuery appeared a few years later, we could use it and that made things a \u003Ci\u003Elot\u003C/i\u003E easier. Portions of the UI were highly customize-able and I built a system of page-specific dialog boxes that would allow the user to make the customizations, provided they had the right permissions.\n\u003Cspace\u003E\nSince the app was now frameless, we went to using AJAX instead of the hidden frame for calls back to the server. A few years later we hired a Java developer who replaced portions of the data layer with a Java service running on a Tomcat server. I worked closely with him. He\u0027s provide me with mock-ups of the JSON he would be returning so I could develop the UI while he developed the back end.  \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E and \u003Cb\u003EMerrill\u003C/b\u003E both were heavily .Net and I didn\u0027t have much opportunity to work in JavaScript as I was scrambling improve my C# skills\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u003C/b\u003E on the other hand was heavily into .Net MVC, but the San Antonio team, who we supported, was developing a new version of their application that uses Angular 2\u002B on the front end. In addition, the local Portland Call Center was developing a replacement for their own application. It was also .Net MVC but it didn\u0027t use Angular. It \u003Ci\u003Edid\u003C/i\u003E use TypeScript in the client. During my time there I had a lot of opportunities to work with TypeScript as a lot of the requests back to the server were AJAX calls and much of the UI components were built on the client.\n\u003C/li\u003E\n\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 3,
    "Name": "ASP (Classic)",
    "Key": "asp",
    "BaseYear": 1998,
    "IsEstimate": true,
    "Text": "I have been using ASP since the late 90s. Even though it\u0027s an older technology, it still shows up every now an then, usually in some legacy application that have matured and is stable enough that no one has been able to make a convincing case to management that it needs to be replaced. My experience with it is as follows:\n\u003Cul\u003E\n\u003Cli\u003E\u003Cb\u003ECorillian Corporation (2000-2004)\u003C/b\u003E\u003Cbr\u003E\nThe bulk of all their online banking sites at this time were ASP coupled with COM objects written  in VB6 or maybe C\u002B\u002B (Not real sure as these were written by another group). There was also a custom version of Basic that was used for the host scripts that pulled data from the banks\u0027 hosts (usually mainframes). I eventually moved into a group that created banking sites for smaller banks and credit unions where the focus was to get the sites done quickly to keep the cost down. These sites were still in ASP but used JScript as the back-end language which I preferred over VBScript that is normally the default.\n\u003C/li\u003E\n\u003Cli\u003E\u003Cb\u003EInnovation Asset Group (IAG) (2004-2014)\u003C/b\u003E\u003Cbr\u003E\nIAG was a startup based in Lake Oswego when I joined the company. As a small company, we had at most 3-4 developers and at some points I was the only developer on the client side. Their main product, Decipher was an ASP-based web application that tracked patent, trademark and invention disclosure data. It had a data layer and a valuation layer, both written in VB.Net which ran as windows services using a third-party wrapper (at that point VB.Net did not support running as a service natively). The initial version used VBScript as the client-side language, which limited the browser it could be used with to IE6. \n\u003Cspace\u003E\nA rewrite several years later switched it to JavaScript and most of the pages used JScript in the back-end as well. JQuery and AJAX were used extensively throughout the application using an efficient custom serialization of the table data using the binary characters 1, 2 and 3 to separate table, row and field data respectively. Pages were rendered in the client, usually using an object that contained an array of rows, which in turn objects that contain an array of fields plus the logic to render the rows. The parent object would render the table and iterate through the objects which would render the rows.\n\u003Cspace\u003E\nI also created an extensive set of debugging and configuration tools that allowed uses to configure the application, add data fields and modify some screens as well as display in-memory data in tabular format. All this was based on user/group permissions.  \n\u003Cspace\u003E\nAt one point, the developers who wrote and managed the data and valuation layers left the company and it was decided to replace the aging VB.Net components with a new back-end based on a Tomcat server and Java. I was responsible for the client side and used AJAX to make REST calls to the back-end.   \n\u003C/li\u003E\n\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 9,
    "Name": "SQL",
    "Key": "sql",
    "BaseYear": 1998,
    "IsEstimate": false,
    "Text": "Not sure exactly when I started using SQL. I know it was probably around 1998 as I was still in California doing development on a Linux server for some local websites. At that time I was doing a lot of PHP/MySQL, using ODBC connections.\n\u003Cspace\u003E\nSQL has been a staple part of my development from the day I picked it up. I must have written thousands of queries to explore databases, create test data, test program execution and check results, even when I\u0027m using Entity Framework for my actual development. Professionally, I\u0027ve used it all through my career:\n\u003Cul\u003E\u003Cli\u003E\nWhen I went to work at \u003Cb\u003ECorillian\u003C/b\u003E in 2000, I wrote a lot of scripts against Microsoft SQL Server databases, mostly to support development. \n\u003C/li\u003E\u003Cli\u003E\nAt \u003Cb\u003EInnovation Asset Group\u003C/b\u003E (IAG) the emphasis was to write generic scripts that would work on both MySQL and MS Server as the main product, Decipher, could be installed to use either database engine. IAG didn\u0027t have a dedicated DB Analyst, so I ended up doing a lot of database installs and configuration, not to mention finding ways to optimize queries for both SQL Server \u003Ci\u003Eand\u003C/i\u003E MySQL.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E was already using Entity Framework in their main applications, but there was still a lot of SQL in the utility applications.\n\u003C/li\u003E\u003Cli\u003E\nAt \u003Cb\u003EMerrill Corporation\u003C/b\u003E I created and edited a lot of stored procedures which were used in the legacy product and the file interfaces to pull data from customer-provided text files and save it to the database. The product dealt with large volumes of insurance data and I often had to find ways to optimize the stored procedures to improve performance.\n\u003Cspace\u003E\nI wrote a script that modified most of the tables in the database to use \u003Cb\u003Enchar\u003C/b\u003E and \u003Cb\u003Envarchar\u003C/b\u003E instead of \u003Cb\u003Echar\u003C/b\u003E and \u003Cb\u003Evarchar\u003C/b\u003E respectively. This was part of a push to use Unicode in their applications.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u003C/b\u003E used stored procedures in their APIs and some of the legacy applications used SQL through an ADO.Net connection with parameterized queries. I created, edited and debugged these stored procedures frequently. \n\u003C/li\u003E\u003C/ol\u003E\n"
  },
  {
    "LanguageEntryId": 10,
    "Name": "Cascading Style Sheets (CSS)",
    "Key": "css",
    "BaseYear": 1998,
    "IsEstimate": false,
    "Text": "I\u0027ve used Cascading Style Sheets since they first appeared, long before bootstrap appeared. \n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003EI Understand the difference between inline, internal and external CSS and when to use them\u003C/b\u003E\u003Cbr\u003E\nI know how to set up the global and section styles, how and when to override it for a specific page and how and when to set style for specific elements.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EI can write CSS from scratch or build from an existing library\u003C/b\u003E\u003Cbr\u003E\nI know how to locate and override CSS classes without tampering with the base definitions and functionality\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EI know how to dynamically position elements and manipulate DOM elements using jQuery or JavaScript directly.\u003C/b\u003E\u003Cbr\u003E\n\u003Clist\u003E\n*Position floating elements\n*Show and hide elements\n*Transitions between states\n*Creating drop down menus and other dynamic controls\n*Partial page refreshes and pushing content into existing elements.\n\u003C/list\u003E\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EI understand responsive layout\u003C/b\u003E\u003Cbr\u003E\nI can write the responsive CSS from scratch or use and existing framework such as Bootstrap\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EI know how to generate CSS programmatically\u003C/b\u003E\u003Cbr\u003E\nEither through server or client-side code or using a CSS preprocessor like LESS\n\u003C/li\u003E\u003C/ul\u003E\n\n\n"
  },
  {
    "LanguageEntryId": 4,
    "Name": "AJAX/WebAPI",
    "Key": "ajax",
    "BaseYear": 2006,
    "IsEstimate": true,
    "Text": "I have been using AJAX or similar technologies for about as long as it\u0027s been around:\n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E was rewriting their existing ASP.Net applications to .Net MVC with an Angular UI. This used AJAX extensively, often using AJAX in two different tiers. The Angular UI communicates back to the MVC framework through AJAX calls to API controllers, which then pass the requests down to the business layer. If the data requested is served from a remote server such as the Portland Call Center, the business layer will then make another AJAX call to the web service on that server.\n\u003Cspace\u003E\nI was involved an all facets of this process, sometimes creating new end-to-end functionality including the API and all the components including the Angular UI. I worked in the Portland Call Center and worked on San Antonio applications remotely. Testing and debugging the APIs independently was accomplished using Swagger locally.\n\u003Cspace\u003E\nThe Portland Call Center was also rewriting of their own application, replacing legacy ASP.Net with .Net Core MVC. This did not use Angular, but it did use TypeScript in the front end. Data operations were a mix of MVC and AJAX, depending on the the page requirements.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EMerrill Corporation\u003C/b\u003E was more traditional in their client/server approach. I don\u0027t remember much AJAX being implemented there at all.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis Financial Solutions\u003C/b\u003E \u003Ci\u003Edid\u003C/i\u003E have a lot of .Net WebAPIs which usually served as the data layer for multiple applications. They had MVC index pages incorporated into the service that briefly documented the API and allowed for some testing/debugging. \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EInnovation Asset Group\u003C/b\u003E originally used a pseudo-AJAX approach using a hidden frame in the first version of their product. When the application was re-written, we began using AJAX calls (based at first on our own code and later using jQuery\u0027s Ajax methods) to ASP pages that would make the call to the data layer and return serialized data. This data was then deserialized in the client using JavaScript and used to re-draw sections of the page using document.innerHTML. As the application matured, more and more of the data layer was moved to API calls, creating a very clear line between the Client and Server sides of the application.\n\u003Cspace\u003E\nLater on, we added a new reporting engine using Java on a Tomcat server. This was when the AJAX model really paid off as no real work was required to adapt to the new data source; all it took was using the new REST URL and adding methods to serialize/deserialize JSON. We \u003Ci\u003Edid\u003C/i\u003E have to enable URL re-writing on the web server and there was some fiddling with the headers to get the session right. \n\u003C/li\u003E\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 1010,
    "Name": "jQuery",
    "Key": "jquery",
    "BaseYear": 2006,
    "IsEstimate": false,
    "Text": "I began using jQuery shortly after its release while working at \u003Cb\u003EInnovation Asset Group\u003C/b\u003E. At first I was a bit skeptical, but it did such a good job at wrapping the CSS queries and interacting with the DOM that it\u0027s usually worth it to include the 100-200kb library.j\n\u003Cspace\u003E\nQuery is actually written in JavaScript, so it isn\u0027t really adding anything to the language, but it makes it easy to do things that would be difficult or impractical to do otherwise. It\u0027s wicked fast and provides cross-browser support:\n\u003Cul\u003E\u003Cli\u003E\nI use jQuery for almost all of my AJAX code from the client. It is very easy to set up, allows you pass in the callback functions and it returns a promise which lets the callbacks to be called in their local scope.\n\u003C/li\u003E\u003Cli\u003E\nI use jQuery to add and remove classes from elements or groups of elements. If the CSS is set up right, this will trigger animations as elements grow or shrink, move for one location to another or fade from one color to another.\n\u003C/li\u003E\u003Cli\u003E\nI sometimes use jQuery to add event handlers to elements based on a CSS class or Id.\n\u003C/li\u003E\u003Cli\u003E\nThe link you clicked to open this popup was created by using a jQuery call to apply function to all elements with a class of \u0022lang-tags\u0022. This function uses the data from the techMapData list to locate and wrap the language names in spans that call the LangDetails page when clicked.\n\u003C/li\u003E\u003C/ul\u003E"
  },
  {
    "LanguageEntryId": 2,
    "Name": "C#",
    "Key": "c",
    "BaseYear": 2011,
    "IsEstimate": true,
    "Text": "C# has been my primary, day-to-day language for the last six years. Before that I used it on a sporadic basis creating back-end utilities and debugging tools.\n\u003Cul\u003E\u003Cli\u003E\nAt \u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E, I used C# with Visual Studio, version 2017 and 2019 on a daily basis (sometimes using an older version to work on legacy code). The emphasis was on clean, concise code that was easy to maintain and adhered to the established best practices. I worked with several groups, including offshore teams using an Agile process that was efficient and well established using three-week sprints. Source code was managed through Git and many of the projects in the lower regions (dev, integration and release) used Continuous Integration. Higher regions (beta and production) were deployed automatically, but required a manual launch. The projects included Web APIs, building business, data and service layers, writing MVC controllers and solving business, performance and security issues. I interfaced routinely with SQL Server using Entity Framework/Link and sometimes calling stored procedures (usually in the APIs). Most of the applications were .Net MVC or .Net Core MVC but occasionally I would need to work on a legacy application written in ASP.Net (WebForms/ASPX).\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EMerrill Corporation\u003C/b\u003E was interesting. Projects there ranged from .Net MVC to Classic ASP with COM objects written in Visual Basic 6. Their main product was a collection of applications that assembled insurance information and generated large, data-intensive documents like Group Insurance Plans, Benefits Packages and voting pamphlets. They were rewriting the UI for their main product from ASP.Net to .Net MVC. In addition to these, there were many other projects for compiling data based on institution/group-specific data, verifying the integrity of the data and formatting the data into printer files (PDFs) and File Interfaces which were the applications that would take customer-provided files. The latter could be comma or tab-delimited, XML, or sometimes a custom format that would require writing a custom parser. \n\u003Cspace\u003E\nI was involved in many of these, creating pages for the UI rewrite, creating a couple file interfaces and made bug fixes several more. I wrote routines and made changes to several of the data-assembly projects and of course did a lot of bug fixes. One file-interface project I wrote involved importing XML files that were over four GB in size (minified, with no unnecessary white space or line breaks). I had to write a custom parser that would go through the file serially on an element-by-element basis and saving the relevant data as it was found. I re-used this code to write a windows forms app that could search through the file and display matching records in a tabular format. This was necessary as no one had a viewer that could open the file and format the XML. This utility was used by the Integration and QA groups to investigate data-import issues.\n\u003Cspace\u003E\nLater projects were done using a test-driven development pattern, using the test cases to develop the components. I was shocked when the components were integrated with no bugs. We used a fake DB, which means that every test group re-created the tables and populated the data it needed. It was definitely worth it in the end.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis Financial Solutions\u003C/b\u003E provides low-maximum credit cards for companies, such as furniture stores and other retailers that issue them to customers who otherwise would have a hard time getting credit. The group I worked for was responsible for creating and maintaining software used by the company\u0027s call center. I was there on a three-month contract during which I got a crash course on the finer points of C# such as lambda expressions, Entity Framework and how large .Net applications should be structured. I was involved in a couple of .Net MVC projects, plus wrote several back-end utilities that extracted data from large files or managed the files referenced by these files.\n\u003C/li\u003E\u003Cli\u003E\nAlthough most of my work at \u003Cb\u003EInnovation Asset Group\u003C/b\u003E was in JavaScript, there was an occasional file interface that needed to be written to deal with flat files provided by the customers. Usually these were C# console apps that could be kicked off by a scheduled task, but sometimes they included a Windows Form UI to allow options to be set or the progress to be monitored. Often these files would only loosely conform to the format they provided and in one case the format would change from section to section as it was a collection of files from various department that each had their own way of doing things. Being such a small company (usually less than 10 employees) it was easier to just accommodate our clients (who tended to be very large corporations) than to try an enforce policies on the data formats we would accept.\n\u003C/li\u003E\u003C/ul\u003E\nBeyond my professional experience, I\u0027ve used several versions of C since the late 1980\u0027s.\n\u003Cul\u003E\u003Cli\u003E\nI first learned C on the Commodore Amiga using the Lattice C Compiler. The Amiga, although powerful for its day had no concept of protecting memory. Address 4 was the only address that could not be written to by the user, which means that if you declare a string pointer and try to load data into it with out first allocating the memory, it would take whatever the value of the pointer is (usually a random number) and overwrite whatever was was in memory, starting at that address. Unless you were \u003Ci\u003Ereally\u003C/i\u003E lucky, this usually resulted in one of three errors: \n\u003Col\u003E\u003Cli\u003E\nThe cursor disappears and never comes back.\n\u003C/li\u003E\u003Cli\u003E\nYou get the \u0027Guru Meditation\u0022 message at the top of the screen (the Amiga equivalent of the \u0022Blue Screen of Death\u0022.\n\u003C/li\u003E\u003Cli\u003E\nYou get \u0022Fireworks Display Mode\u0022 which is what happens when you overwrite display memory or logic with random data.\n\u003C/li\u003E\u003C/ol\u003E\nAll three of these required hard boot to recover and any unsaved anything was gone.\n\u003Cspace\u003E\nI took a class at Sun Microsystems through McDonnell Douglas and that really made the language clear to me, especially how pointers and memory management work. After that, I was hooked. I wrote some utilities for the Amiga Workbench (More like filling out taxes than programming at times) and a text reader I wrote was used in the floppy-based Amiga magazine published in Ranch Cucamonga  \u003Ci\u003EJump Disk\u003C/i\u003E for a few years.\n\u003C/li\u003E\u003Cli\u003E\nI did some C on Sun workstations at McDonnell Douglas \u2013 the Interleaf Publishing System ran on Sun workstations and used LISP as it\u0027s scripting language (don\u0027t get me started on LISP). I learned in LISP was how to write a function to call a C program. After that, since Sun UNIX included a native c compiler, I made all my scripts in C. These could be launched from Interleaf\u0027s menu system and included mostly utility scripts and a filter to convert a TIFF image to the native Interleaf raster format. \n\u003C/li\u003E\u003Cli\u003E\nWhen I moved to the PC and Windows, I did some coding with Quick C, Quick C for Windows and Visual C\u002B\u002B 5.0 with the Microsoft Foundation Classes (MFC). However C and MFC just weren\u0027t a good fit what I needed as I was moving toward web development, so I shelved C for a while and moved on to other languages with a similar syntax like JavaScript, PERL and PHP.\n\u003C/li\u003E\u003C/ul\u003E\n"
  },
  {
    "LanguageEntryId": 1012,
    "Name": "Dot Net",
    "Key": "dotnet",
    "BaseYear": 2011,
    "IsEstimate": false,
    "Text": "\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003ECorillian Corporation\u003C/b\u003E I was first introduced to .Net during a demonstration by Scott Hanselman, then an employee of the company. Over the next couple of years Corillian\u0027s engineering group began working on a core framework using .Net Forms, but it didn\u0027t become mainstream within the company until after I left the company. I did do some experimentation with .Net and created some personal projects, but I never officially worked on any .Net projects while I was there.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EInnovation Asset Group\u003C/b\u003E used Classic ASP with a back-end data layer written in VB.Net which ran as a service. At one point, the developers responsible for maintaining the code left and I would occasionally deal with issues. I also did extensive analysis of the code and wrote suggestions on how to rewrite it.\n \u003Cspace\u003E\nI wrote a series of file interfaces in C# to import data from customer-supplied files which included tab/comma-delimited files, and sometimes Excel spreadsheets.\n\u003C/li\u003E\u003Cli\u003E\nDuring my three-month contract with \u003Cb\u003EGenesis Financial Solutions\u003C/b\u003E, I worked on .Net MVC applications that made calls to .Net WebAPIs and also used C# to create several utilities to extract files that were stored in a database.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EMerrill Corporation\u003C/b\u003E was a smorgasbord of .Net technologies. Initially I was tasked with fixing issues from their backlog and these included everything from ASP, Visual Basic and .Net Forms. I also wrote a couple of file interfaces, did some work on their publishing engine and had some involvement with the .Net MVC rewrite of their main product used to configure their publishing platform.\n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u003C/b\u003E Was also rewriting their ASP.Net applications in .Net MVC and .Net Core. I was involved in the porting of the Portland Office\u0027s main product to .Net MVC and integrating it into Portal, which was another .Net MVC application through which all other apps were accessed. The web application was hosted in San Antonio, but the Portland data was located in Portland and .Net WebAPIs were used for the data layer.  \n\u003Cspace\u003E\nThe Portland Office had an application of its own that they were rewriting in .Net Core and I was involved in that as well until the Portland office was closed in October 2019 and the project abandoned. I and the rest of the Portland development team remained on, working from home. \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003EPersonal\u003C/b\u003E After leaving SWBC, I have been working with .Net Core Blazor. It\u0027s the next iteration of .Net Core and I believe it will be the successful as the next step in .Net\u0027s evolution. Not sure if anyone\u0027s using it yet in production, but there\u0027s a lot of interest and so I want to be ready.\n\u003C/li\u003E\u003C/ul\u003E\n\n"
  },
  {
    "LanguageEntryId": 6,
    "Name": "TypeScript",
    "Key": "typescript",
    "BaseYear": 2014,
    "IsEstimate": false,
    "Text": "I did quite a bit of TypeScript development during my time at \u003Cb\u003ESouthwest Business Corporation\u003C/b\u003E (SWBC)\n\u003Cul\u003E\u003Cli\u003E\nThe main SWBC development group in San Antonio, Texas uplifted their legacy applications to a new set of applications (Portal) using .Net MVC/WebAPI on the back-end and Angular 4 for the UI which uses TypeScript. The application used MVC to build the pages and load the initial data which was serialized as part of the HTML. Once the page was built, the Angular/TypeScript took over and handled user request, using Angular\u0027s AJAX methods to call the WebAPI, which in turn performed any server-side operations that were needed then either navigated to another page through MVC or returned JSON back to the client and Angular would decide what to do next. I was involved in implementing the application maintained by the Portland Call Center as part of the Portal application.\n\u003C/li\u003E\n\u003Cli\u003E\nThe development team for the Portland Call Center began a project to uplift their product, SureTrack from ASP.Net to .Net Core MVC. This did not use Angular, but it \u003Ci\u003Edid\u003C/i\u003E use TypeScript and I did a lot of the client-side development. This was an interesting project as it gave me a chance to use TypeScript outside the Angular environment. I wrote several basic components including a tab control and a grid control. Unfortunately, in October, 2019, the Portland Call Center was closed and the project abandoned. The development team was retained as remote employees, but moved on to other projects in support of the San Antonio Team.\n\u003C/li\u003E\n\u003C/ul\u003E\nI have mixed feelings about TypeScript. It \u003Ci\u003Eseems\u003C/i\u003E like it\u0027s aimed at C#/Java developers that can\u0027t get their heads around the prototypical inheritance model that JavaScript uses. However, coming from JavaScript development, it feels a bit like learning German to write documentation in German so it can be translated back to my native English. I worry that it will lead to a generation of web developers that understand TypeScript, but don\u0027t understand the nuts and bolts of JavaScript. It\u0027s the quirks in JavaScript that really gives it it\u0027s power.\n\u003Cspace\u003E\nOn the other hand, it \u003Ci\u003Edoes\u003C/i\u003E make for elegant source code (yes, even if carefully written, JavaScript can be a bit cryptic and in the wrong hands can lead to some marvelously undecipherable code), and developers familiar with C#/Java will have a much easier time figuring it out."
  },
  {
    "LanguageEntryId": 7,
    "Name": "Entity Framework (EF)",
    "Key": "ef",
    "BaseYear": 2014,
    "IsEstimate": false,
    "Text": "I used Entity Framework for may last three employers: \n\u003Cul\u003E\u003Cli\u003E\n\u003Cb\u003EGenesis\u003C/b\u003E gave me my first exposure to Entity Framework, mostly through making changes to existing code. That\u0027s also where I was first exposed to lambda expressions in C#, where I made changes to existing code. By the time I left Genesis, I hadn\u0027t mastered EF yet, but I was definitely intrigued. \n\u003C/li\u003E\u003Cli\u003E\nI got a lot more exposure to EF at \u003Cb\u003EMerrill Corporation\u003C/b\u003E. They used a database-first approach and used Visual Studio to generate the models in the application. The file interfaces I created used Entity Framework and dealt with large and complex data sets requiring thousands of records to be created. Here I not only became proficient in EF and Linq, but in optimizing the code and timing the SaveChanges calls as well. \n\u003C/li\u003E\u003Cli\u003E\n\u003Cb\u003ESWBC\u0027s\u003C/b\u003E Portland Call Center used Entity Framework extensively in their main application\u0027s rewrite. They also used a \u003Cb\u003EDatabase-First\u003C/b\u003E model, creating the entity models and context manually. Database changes were saved in source control as SQL scripts that had to be run manually as part of the deployments to QA, Beta and Production.\n\u003Cspace\u003E\nThe San Antonio Team used a \u003Cb\u003ECode-First\u003C/b\u003E approach in their application rewrites, which made deployments a lot easier. They had a much larger team than Portland and had \u003Cb\u003EContinuous Integration\u003C/b\u003E set up for most of the applications. Applying migrations was part of the build process which meant that when a pull request was approved, there were few, if any manual steps to building/deploying code and updating the database. \n\u003C/li\u003E\u003C/ul\u003E\n"
  },
  {
    "LanguageEntryId": 1011,
    "Name": "LINQ",
    "Key": "linq",
    "BaseYear": 2014,
    "IsEstimate": false,
    "Text": "After leaving Innovation Asset Group and being thrust into the world of .Net, one of the first hurdles I faced was getting my head around \u003Cb\u003ELINQ\u003C/b\u003E (\u003Ci\u003ELanguage-Integrated Query\u003C/i\u003E). It was pretty cryptic at first but once I understood what a lambda expression really was, I was hooked. \n\u003Cul\u003E\u003Cli\u003E\nI use it for database queries through Entity Framework, but it works just as well on any C# List (or any other collection based on IEnumerable). \n\u003C/li\u003E\u003Cli\u003E\nIt \u003Ci\u003Evastly\u003C/i\u003E simplifies queries and  pulling data from lists. Couple it with Entity Framework and it makes dealing with the database feel like you\u0027re using data that\u0027s already in your code.\n\u003C/li\u003E\u003Cli\u003E\nLambda expressions can serve as a shorthand for creating anonymous functions, useful for calling delegate functions and performing operations on list elements. \n\u003C/li\u003E\u003Cli\u003E\nOther languages, such as ECMAScript 6 and TypeScript are beginning to incorporate \u003Ci\u003Earrow functions\u003C/i\u003E (guess they didn\u0027t want to give the nod to .Net) as a shorthand for declaring anonymous in-line functions.\n\u003C/li\u003E\u003C/ul\u003E\n"
  }
]